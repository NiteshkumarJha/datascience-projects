{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LTFS_Data_Science_FinHack_2_RF_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lW6Vh68CvHr9"
      },
      "source": [
        "# **LTFS Data Science FinHack 2**\n",
        "\n",
        "## **Problem statement**\n",
        "\n",
        "LTFS receives a lot of requests for its various finance offerings that include housing loan, two-wheeler loan, real estate financing and micro loans. The number of applications received is something that varies a lot with season. Going through these applications is a manual process and is tedious. Accurately forecasting the number of cases received can help with resource and manpower management resulting into quick response on applications and more efficient processing.\n",
        "\n",
        "We have been appointed with the task of forecasting daily cases for **next 3 months for 2 different business segments** at the **country level** keeping in consideration the following major Indian festivals (inclusive but not exhaustive list): Diwali, Dussehra, Ganesh Chaturthi, Navratri, Holi etc. (We are free to use any publicly available open source external datasets). Some other examples could be:\n",
        "\n",
        " + Weather\n",
        " + Macroeconomic variables\n",
        "\n",
        "we also note that the external dataset must belong to a reliable source.\n",
        "\n",
        "## **Data Dictionary**\n",
        "\n",
        "The train data has been provided in the following way:\n",
        "\n",
        " + For business segment 1, historical data has been made available at branch ID level\n",
        " + For business segment 2, historical data has been made available at State level.\n",
        " \n",
        "\n",
        "## **Train File**\n",
        "\n",
        "|Variable|\tDefinition|\n",
        "|:------:|:----------:|\n",
        "|application_date|Date of application|\n",
        "|application_date|\tDate of application|\n",
        "|segment|\tBusiness Segment (1/2)|\n",
        "|branch_id|\tAnonymised id for branch at which application was received|\n",
        "|state|\tState in which application was received (Karnataka, MP etc.)|\n",
        "|zone|\tZone of state in which application was received (Central, East etc.)|\n",
        "|case_count|\t(Target) Number of cases/applications received|\n",
        "\n",
        "## **Test File**\n",
        "\n",
        "Forecasting needs to be done at country level for the dates provided in test set for each segment.\n",
        "\n",
        "|Variable|\tDefinition|\n",
        "|:------:|:----------:|\n",
        "|id|\tUnique id for each sample in test set|\n",
        "|application_date|\tDate of application|\n",
        "| segment|\tBusiness Segment (1/2)|\n",
        "\n",
        "## **Evaluation**\n",
        "\n",
        "**Evaluation Metric**\n",
        "\n",
        "The evaluation metric for scoring the forecasts is MAPE (Mean Absolute Percentage Error) M with the formula:\n",
        "\n",
        "$$M = \\frac{100}{n}\\sum_{t = 1}^{n}|\\frac{A_t - F_t}{A_t}|$$\n",
        " \n",
        "Where $A_t$ is the actual value and $F_t$ is the forecast value.\n",
        "\n",
        "\n",
        "The Final score is calculated using $MAPE$ for both the segments using the formula:\n",
        "\n",
        "$Final Score = 0.5*MAPE_{Segment1} + 0.5*MAPE_{Segment2}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N-vGpTKiAR1Y"
      },
      "source": [
        "## **Getting started**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xYFLOVn80m5U"
      },
      "source": [
        "### **Importing libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Et1FYa3Eu9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cd399a40-c684-4f0a-8661-1a419a604676"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4wCxeTR3u6yN",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as ss\n",
        "%matplotlib inline\n",
        "\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 100)\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-LexknjbArnb"
      },
      "source": [
        "### **Reading data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMaEr8BlDxqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting the path\n",
        "import os\n",
        "path = \"/content/drive/My Drive/Colab Notebooks (1)/LTFS Data Science FinHack 2\"\n",
        "os.chdir(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op5SwGPgDxqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the dataset\n",
        "train = pd.read_csv(\"./Input/train_fwYjLYX.csv\")\n",
        "test = pd.read_csv(\"./Input/test_1eLl9Yf.csv\")\n",
        "holidays = pd.read_csv(\"./Input/holiday_list_2017_2018_2019.csv\")\n",
        "Sample_submission = pd.read_csv(\"./Input/sample_submission_IIzFVsf.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-iWd6d4FBz5q"
      },
      "source": [
        "## **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2OYM4vA5B3Kf",
        "outputId": "223241bd-a7f2-409e-f1c4-a060b3dfb932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application_date</th>\n",
              "      <th>segment</th>\n",
              "      <th>branch_id</th>\n",
              "      <th>state</th>\n",
              "      <th>zone</th>\n",
              "      <th>case_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>WEST BENGAL</td>\n",
              "      <td>EAST</td>\n",
              "      <td>40.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-04-03</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>WEST BENGAL</td>\n",
              "      <td>EAST</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-04-04</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>WEST BENGAL</td>\n",
              "      <td>EAST</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-04-05</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>WEST BENGAL</td>\n",
              "      <td>EAST</td>\n",
              "      <td>113.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-04-07</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>WEST BENGAL</td>\n",
              "      <td>EAST</td>\n",
              "      <td>76.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  application_date  segment  branch_id        state  zone  case_count\n",
              "0       2017-04-01        1       1.00  WEST BENGAL  EAST       40.00\n",
              "1       2017-04-03        1       1.00  WEST BENGAL  EAST        5.00\n",
              "2       2017-04-04        1       1.00  WEST BENGAL  EAST        4.00\n",
              "3       2017-04-05        1       1.00  WEST BENGAL  EAST      113.00\n",
              "4       2017-04-07        1       1.00  WEST BENGAL  EAST       76.00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0oyr1g5CQa8n",
        "outputId": "a320294d-e151-4f73-c0a4-5fc3c5ed1850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Data preprocessing function\n",
        "train_v2 = pd.DataFrame(train.groupby(['application_date', 'segment'])['case_count'].sum()).reset_index()\n",
        "train_v2.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application_date</th>\n",
              "      <th>segment</th>\n",
              "      <th>case_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>1</td>\n",
              "      <td>299.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2</td>\n",
              "      <td>897.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-04-02</td>\n",
              "      <td>2</td>\n",
              "      <td>605.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-04-03</td>\n",
              "      <td>1</td>\n",
              "      <td>42.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-04-03</td>\n",
              "      <td>2</td>\n",
              "      <td>2016.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  application_date  segment  case_count\n",
              "0       2017-04-01        1      299.00\n",
              "1       2017-04-01        2      897.00\n",
              "2       2017-04-02        2      605.00\n",
              "3       2017-04-03        1       42.00\n",
              "4       2017-04-03        2     2016.00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf0RNjnTF5Iy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "72457dda-e6d0-4a70-b50e-5917d913ca34"
      },
      "source": [
        "holidays['application_date'] = pd.to_datetime(holidays['DATE'])\n",
        "holidays = holidays[['application_date', 'HOLIDAY']]\n",
        "holidays.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application_date</th>\n",
              "      <th>HOLIDAY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>New Year's Day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-01-14</td>\n",
              "      <td>Makar Sankranti / Pongal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-01-26</td>\n",
              "      <td>Republic Day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-02-24</td>\n",
              "      <td>Maha Shivaratri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-03-13</td>\n",
              "      <td>Holi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  application_date                   HOLIDAY\n",
              "0       2017-01-01            New Year's Day\n",
              "1       2017-01-14  Makar Sankranti / Pongal\n",
              "2       2017-01-26              Republic Day\n",
              "3       2017-02-24           Maha Shivaratri\n",
              "4       2017-03-13                      Holi"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FargfjjEFmJp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "c69b4a0d-e5e3-4c76-9dae-c787ae028eed"
      },
      "source": [
        "Diwali_HOLIDAY = pd.DataFrame()\n",
        "diwali = [\"2017-10-17\", \"2017-10-18\", \"2017-10-19\", \"2017-10-20\", \"2017-10-21\",\n",
        "          \"2018-11-05\", \"2018-11-06\", \"2018-11-07\", \"2018-11-08\", \"2018-11-09\",\n",
        "          \"2019-10-25\", \"2019-10-26\", \"2019-10-27\", \"2019-10-28\", \"2019-10-29\"]\n",
        "\n",
        "Diwali_HOLIDAY['application_date'] = diwali\n",
        "Diwali_HOLIDAY['application_date'] = pd.to_datetime(Diwali_HOLIDAY['application_date'])\n",
        "Diwali_HOLIDAY['Diwali_HOLIDAY'] = 1\n",
        "# temp\n",
        "print(Diwali_HOLIDAY)\n",
        "\n",
        "Dussehra_HOLIDAY = pd.DataFrame()\n",
        "Dussehra = [\"2017-09-22\",\"2017-09-23\",\"2017-09-24\", \"2017-09-25\", \"2017-09-26\",\n",
        "            \"2017-09-27\", \"2017-09-28\", \"2017-09-29\", \"2017-09-30\",\n",
        "            \"2018-10-11\", \"2018-10-12\", \"2018-10-13\", \"2018-10-14\", \"2018-10-15\",\n",
        "            \"2018-10-16\", \"2018-10-17\", \"2018-10-18\", \"2018-10-19\",\n",
        "            \"2019-09-30\", \"2019-10-01\", \"2019-10-02\", \"2019-10-03\", \"2019-10-04\",\n",
        "            \"2019-10-05\", \"2019-10-06\", \"2019-10-07\", \"2019-10-08\"]\n",
        "\n",
        "Dussehra_HOLIDAY['application_date'] = Dussehra\n",
        "Dussehra_HOLIDAY['application_date'] = pd.to_datetime(Dussehra_HOLIDAY['application_date'])\n",
        "Dussehra_HOLIDAY['Dussehra_HOLIDAY'] = 1\n",
        "# temp\n",
        "print(Dussehra_HOLIDAY)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   application_date  Diwali_HOLIDAY\n",
            "0        2017-10-17               1\n",
            "1        2017-10-18               1\n",
            "2        2017-10-19               1\n",
            "3        2017-10-20               1\n",
            "4        2017-10-21               1\n",
            "5        2018-11-05               1\n",
            "6        2018-11-06               1\n",
            "7        2018-11-07               1\n",
            "8        2018-11-08               1\n",
            "9        2018-11-09               1\n",
            "10       2019-10-25               1\n",
            "11       2019-10-26               1\n",
            "12       2019-10-27               1\n",
            "13       2019-10-28               1\n",
            "14       2019-10-29               1\n",
            "   application_date  Dussehra_HOLIDAY\n",
            "0        2017-09-22                 1\n",
            "1        2017-09-23                 1\n",
            "2        2017-09-24                 1\n",
            "3        2017-09-25                 1\n",
            "4        2017-09-26                 1\n",
            "5        2017-09-27                 1\n",
            "6        2017-09-28                 1\n",
            "7        2017-09-29                 1\n",
            "8        2017-09-30                 1\n",
            "9        2018-10-11                 1\n",
            "10       2018-10-12                 1\n",
            "11       2018-10-13                 1\n",
            "12       2018-10-14                 1\n",
            "13       2018-10-15                 1\n",
            "14       2018-10-16                 1\n",
            "15       2018-10-17                 1\n",
            "16       2018-10-18                 1\n",
            "17       2018-10-19                 1\n",
            "18       2019-09-30                 1\n",
            "19       2019-10-01                 1\n",
            "20       2019-10-02                 1\n",
            "21       2019-10-03                 1\n",
            "22       2019-10-04                 1\n",
            "23       2019-10-05                 1\n",
            "24       2019-10-06                 1\n",
            "25       2019-10-07                 1\n",
            "26       2019-10-08                 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-9XPZmIF03e3"
      },
      "source": [
        "## **Feature engineering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hjw7wu0Xwl-g",
        "colab": {}
      },
      "source": [
        "def feature_eng(train_v2):\n",
        "    train_v2['application_date'] = pd.to_datetime(train_v2['application_date'])\n",
        "\n",
        "    train_v2 = pd.merge(train_v2, holidays, on = 'application_date', how = 'left')\n",
        "    train_v2['HOLIDAY'] = train_v2['HOLIDAY'].fillna('Non-Holiday')\n",
        "    train_v2['Holiday_flag'] = np.where(train_v2['HOLIDAY'] == 'Non-Holiday', 0, 1)\n",
        "\n",
        "    train_v2 = pd.merge(train_v2, Diwali_HOLIDAY, on = 'application_date', how = 'left')\n",
        "    train_v2['Diwali_HOLIDAY'] = train_v2['Diwali_HOLIDAY'].fillna(0)\n",
        "\n",
        "    train_v2 = pd.merge(train_v2, Dussehra_HOLIDAY, on = 'application_date', how = 'left')\n",
        "    train_v2['Dussehra_HOLIDAY'] = train_v2['Dussehra_HOLIDAY'].fillna(0)\n",
        "\n",
        "    train_v2['year'] = train_v2['application_date'].dt.year\n",
        "    train_v2['Month'] = train_v2['application_date'].dt.month\n",
        "    train_v2['Date'] = train_v2['application_date'].dt.day\n",
        "    train_v2['weekday'] = train_v2['application_date'].dt.weekday_name\n",
        "\n",
        "    Seasons = {6: 'Monsoon', 7: 'Monsoon', 8: 'Monsoon', 9: 'Monsoon',\n",
        "               10: 'Winter', 11: 'Winter', 12: 'Winter', 1: 'Winter',\n",
        "               2: 'Summer', 3: 'Summer', 4: 'Summer', 5: 'Summer'}\n",
        "  \n",
        "    train_v2['Seasons'] = train_v2['Month'].map(Seasons)\n",
        "\n",
        "    train_v2['segment'] = np.where(train_v2['segment'] == 1, 1, 0)\n",
        "\n",
        "    Month_Index = {4: 0.5, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 1: 1, 2: 1, 3: 1.5}\n",
        "\n",
        "    train_v2['Month_Index'] = train_v2['Month'].map(Month_Index)\n",
        "\n",
        "    Date_index = {1 : 0.5,2 : 0.5,3 : 0.5,4 : 0.5,5 : 0.5,6 : 0.5,7 : 0.5,8 : 0.5,9 : 0.5,10 : 0.5,\n",
        "                  11 : 1,12 : 1,13 : 1.5,14 : 1.5,15 : 1.5,16 : 1.5,17 : 1.5,18 : 1.5,19 : 1.5,20 : 1.5,21 : 1.5,\n",
        "                  22 : 1.5,23 : 1,24 : 1,25 : 1,26 : 1,27 : 1,28 : 1,29 : 0.5,30 : 0.5,31 : 0.5}\n",
        "\n",
        "    train_v2['Date_index'] = train_v2['Date'].map(Date_index)\n",
        "\n",
        "    dummy_col = ['weekday', 'Seasons']\n",
        "    temp = train_v2[dummy_col]\n",
        "    temp = pd.get_dummies(temp)\n",
        "\n",
        "    train_v2 = train_v2.drop(dummy_col, axis = 1)\n",
        "    train_v2 = pd.concat([train_v2, temp], axis = 1)\n",
        "\n",
        "    train_v2 = train_v2.drop(['application_date','HOLIDAY'], axis = 1)\n",
        "  \n",
        "    return train_v2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fzr862rsNmhw"
      },
      "source": [
        "## **Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5uGscrl28YVj"
      },
      "source": [
        "### **Creating X and y**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "77zMeiRZ8Rkt",
        "outputId": "09a09d8d-5304-4e72-c872-97c730b97af9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "X = train_v2.drop(['case_count'], axis = 1)\n",
        "y = np.log(train_v2['case_count'])\n",
        "\n",
        "X = feature_eng(X)\n",
        "\n",
        "X_train = X\n",
        "y_train = y\n",
        "\n",
        "print(\"Shape of features :\", X.shape)\n",
        "print(\"Shape of labels :\", y.shape)\n",
        "\n",
        "X.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of features : (1650, 19)\n",
            "Shape of labels : (1650,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>segment</th>\n",
              "      <th>Holiday_flag</th>\n",
              "      <th>Diwali_HOLIDAY</th>\n",
              "      <th>Dussehra_HOLIDAY</th>\n",
              "      <th>year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Date</th>\n",
              "      <th>Month_Index</th>\n",
              "      <th>Date_index</th>\n",
              "      <th>weekday_Friday</th>\n",
              "      <th>weekday_Monday</th>\n",
              "      <th>weekday_Saturday</th>\n",
              "      <th>weekday_Sunday</th>\n",
              "      <th>weekday_Thursday</th>\n",
              "      <th>weekday_Tuesday</th>\n",
              "      <th>weekday_Wednesday</th>\n",
              "      <th>Seasons_Monsoon</th>\n",
              "      <th>Seasons_Summer</th>\n",
              "      <th>Seasons_Winter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2017</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2017</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2017</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2017</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2017</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   segment  Holiday_flag  Diwali_HOLIDAY  Dussehra_HOLIDAY  year  Month  Date  \\\n",
              "0        1             0            0.00              0.00  2017      4     1   \n",
              "1        0             0            0.00              0.00  2017      4     1   \n",
              "2        0             0            0.00              0.00  2017      4     2   \n",
              "3        1             0            0.00              0.00  2017      4     3   \n",
              "4        0             0            0.00              0.00  2017      4     3   \n",
              "\n",
              "   Month_Index  Date_index  weekday_Friday  weekday_Monday  weekday_Saturday  \\\n",
              "0         0.50        0.50               0               0                 1   \n",
              "1         0.50        0.50               0               0                 1   \n",
              "2         0.50        0.50               0               0                 0   \n",
              "3         0.50        0.50               0               1                 0   \n",
              "4         0.50        0.50               0               1                 0   \n",
              "\n",
              "   weekday_Sunday  weekday_Thursday  weekday_Tuesday  weekday_Wednesday  \\\n",
              "0               0                 0                0                  0   \n",
              "1               0                 0                0                  0   \n",
              "2               1                 0                0                  0   \n",
              "3               0                 0                0                  0   \n",
              "4               0                 0                0                  0   \n",
              "\n",
              "   Seasons_Monsoon  Seasons_Summer  Seasons_Winter  \n",
              "0                0               1               0  \n",
              "1                0               1               0  \n",
              "2                0               1               0  \n",
              "3                0               1               0  \n",
              "4                0               1               0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S2vCgkCZ9aXR"
      },
      "source": [
        "### **Splitting data into train, validation and test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WLxZ8UzO9Y_7",
        "colab": {}
      },
      "source": [
        "# # Dividing data into train and validation set\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# validation_percent = 0.30\n",
        "# test_percent = 0.50\n",
        "# seed = 786\n",
        "\n",
        "# X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size = validation_percent, random_state = seed)\n",
        "# X_validation, X_test, y_validation, y_test = train_test_split(X_validation, y_validation, test_size = test_percent, random_state = seed)\n",
        "\n",
        "# # Shape of data\n",
        "# print(\"Number of rows and columns in train dataset:\",X_train.shape)\n",
        "# print(\"Number of rows and columns in validation dataset:\",X_validation.shape)\n",
        "# print(\"Number of rows and columns in test dataset:\",X_test.shape)\n",
        "\n",
        "# print(\"Number of rows and columns in target variable for training:\",y_train.shape)\n",
        "# print(\"Number of rows and columns in target variable for validation:\",y_validation.shape)\n",
        "# print(\"Number of rows and columns in target variable for test:\",y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aDeSbMvS-Xyk"
      },
      "source": [
        "### **Model evualuation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fZRne4q2-aRo",
        "colab": {}
      },
      "source": [
        "import sklearn.metrics as sklm\n",
        "from sklearn.svm import LinearSVR, SVR\n",
        "from sklearn.linear_model import LinearRegression, SGDRegressor, Lasso, Ridge,  PassiveAggressiveRegressor, Perceptron, ElasticNet, LassoLars, BayesianRidge, HuberRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor, NearestCentroid\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor, GradientBoostingRegressor \n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.pipeline import Pipeline\n",
        "from time import time\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, r2_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6xF8DfKa_uWz",
        "colab": {}
      },
      "source": [
        "def mape(forecast, actual):\n",
        "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))\n",
        "    return mape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MZpR0QC6-dZl",
        "colab": {}
      },
      "source": [
        "def accuracy_summary(Regressor, x_train, y_train):\n",
        "    t0 = time()\n",
        "    model = Regressor.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_train)\n",
        "    train_test_time = time() - t0\n",
        "    accuracy = r2_score(y_train, y_pred)\n",
        "    #accuracy = mape(y_pred, y_train)\n",
        "    return accuracy, train_test_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kt8kvUyF-l2y",
        "colab": {}
      },
      "source": [
        "seed = 123\n",
        "names = [\"Linear Regression\", \"Lasso\",\"Ridge\", \"ElasticNet\", \"LassoLars\", \"BayesianRidge\",\n",
        "         \"HuberRegressor\",\"SGDRegressor\", \"Linear SVR\", \n",
        "         \"Support Vector Machine with RBF kernel\",\"Passive-Aggresive\",\"KNeighborsRegressor\",\n",
        "         \"DecisionTreeRegressor\",\"RandomForestRegressor\",\"AdaBoostRegressor\", \n",
        "         \"GradientBoostingRegressor\", \"XGBRegressor-linear\"]\n",
        "\n",
        "Regressors = [\n",
        "    LinearRegression(),\n",
        "    Lasso(random_state=seed),\n",
        "    Ridge(random_state=seed),\n",
        "    ElasticNet(random_state=seed),\n",
        "    LassoLars(),\n",
        "    BayesianRidge(),\n",
        "    HuberRegressor(),\n",
        "    SGDRegressor(random_state=seed),\n",
        "    LinearSVR(random_state=seed),\n",
        "    SVR(),\n",
        "    PassiveAggressiveRegressor(random_state=seed),\n",
        "    KNeighborsRegressor(),\n",
        "    DecisionTreeRegressor(random_state=seed),\n",
        "    RandomForestRegressor(random_state=seed, n_estimators=500),\n",
        "    AdaBoostRegressor(random_state=seed, n_estimators=500),\n",
        "    GradientBoostingRegressor(loss = 'huber', random_state=seed, n_estimators=500),\n",
        "    XGBRegressor(n_estimators=500, random_state=seed),\n",
        "    XGBRegressor(n_estimators=500, random_state=seed, objective='count:poisson'),\n",
        "    XGBRegressor(n_estimators=500, random_state=seed, objective='reg:gamma'),\n",
        "    XGBRegressor(n_estimators=500, random_state=seed, objective='reg:tweedie')\n",
        "    ]\n",
        "\n",
        "zipped_reg = zip(names,Regressors)\n",
        "\n",
        "def Regressor_comparator(Regressor=zipped_reg):\n",
        "    result = []\n",
        "    for n,c in Regressor:\n",
        "        checker_pipeline = Pipeline([\n",
        "            ('Regressor', c)\n",
        "        ])\n",
        "        print(\"Validation result for {}\".format(n))\n",
        "        print (c)\n",
        "        reg_accuracy,tt_time = accuracy_summary(checker_pipeline, X_train, y_train)\n",
        "        result.append((n,reg_accuracy,tt_time))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m7q5S7sv-quc",
        "outputId": "d667fe32-8374-43e2-e8c9-f8c96b8eaa2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Regression_result = Regressor_comparator()\n",
        "Regression_result"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation result for Linear Regression\n",
            "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
            "Validation result for Lasso\n",
            "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
            "      normalize=False, positive=False, precompute=False, random_state=123,\n",
            "      selection='cyclic', tol=0.0001, warm_start=False)\n",
            "Validation result for Ridge\n",
            "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
            "      normalize=False, random_state=123, solver='auto', tol=0.001)\n",
            "Validation result for ElasticNet\n",
            "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
            "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
            "           random_state=123, selection='cyclic', tol=0.0001, warm_start=False)\n",
            "Validation result for LassoLars\n",
            "LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,\n",
            "          fit_path=True, max_iter=500, normalize=True, positive=False,\n",
            "          precompute='auto', verbose=False)\n",
            "Validation result for BayesianRidge\n",
            "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,\n",
            "              compute_score=False, copy_X=True, fit_intercept=True,\n",
            "              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,\n",
            "              normalize=False, tol=0.001, verbose=False)\n",
            "Validation result for HuberRegressor\n",
            "HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,\n",
            "               tol=1e-05, warm_start=False)\n",
            "Validation result for SGDRegressor\n",
            "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
            "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
            "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
            "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=123,\n",
            "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
            "             warm_start=False)\n",
            "Validation result for Linear SVR\n",
            "LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
            "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
            "          random_state=123, tol=0.0001, verbose=0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation result for Support Vector Machine with RBF kernel\n",
            "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
            "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
            "Validation result for Passive-Aggresive\n",
            "PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,\n",
            "                           epsilon=0.1, fit_intercept=True,\n",
            "                           loss='epsilon_insensitive', max_iter=1000,\n",
            "                           n_iter_no_change=5, random_state=123, shuffle=True,\n",
            "                           tol=0.001, validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "Validation result for KNeighborsRegressor\n",
            "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                    weights='uniform')\n",
            "Validation result for DecisionTreeRegressor\n",
            "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
            "                      max_features=None, max_leaf_nodes=None,\n",
            "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                      min_samples_leaf=1, min_samples_split=2,\n",
            "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                      random_state=123, splitter='best')\n",
            "Validation result for RandomForestRegressor\n",
            "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
            "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "                      max_samples=None, min_impurity_decrease=0.0,\n",
            "                      min_impurity_split=None, min_samples_leaf=1,\n",
            "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                      n_estimators=500, n_jobs=None, oob_score=False,\n",
            "                      random_state=123, verbose=0, warm_start=False)\n",
            "Validation result for AdaBoostRegressor\n",
            "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
            "                  n_estimators=500, random_state=123)\n",
            "Validation result for GradientBoostingRegressor\n",
            "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
            "                          init=None, learning_rate=0.1, loss='huber',\n",
            "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
            "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                          min_samples_leaf=1, min_samples_split=2,\n",
            "                          min_weight_fraction_leaf=0.0, n_estimators=500,\n",
            "                          n_iter_no_change=None, presort='deprecated',\n",
            "                          random_state=123, subsample=1.0, tol=0.0001,\n",
            "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
            "Validation result for XGBRegressor-linear\n",
            "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
            "             max_depth=3, min_child_weight=1, missing=None, n_estimators=500,\n",
            "             n_jobs=1, nthread=None, objective='reg:linear', random_state=123,\n",
            "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "             silent=None, subsample=1, verbosity=1)\n",
            "[10:16:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Linear Regression', 0.6227758992591237, 0.007465362548828125),\n",
              " ('Lasso', 0.04081807986529795, 0.004074573516845703),\n",
              " ('Ridge', 0.622768967049937, 0.003392934799194336),\n",
              " ('ElasticNet', 0.04579374891566246, 0.003769397735595703),\n",
              " ('LassoLars', 0.0, 0.003196239471435547),\n",
              " ('BayesianRidge', 0.6227363446971127, 0.0044384002685546875),\n",
              " ('HuberRegressor', 0.5515341700417602, 0.06464385986328125),\n",
              " ('SGDRegressor', -1.6031283825632608e+30, 0.024270296096801758),\n",
              " ('Linear SVR', -0.271237260866541, 0.13211464881896973),\n",
              " ('Support Vector Machine with RBF kernel',\n",
              "  -0.009709019226528337,\n",
              "  0.34661316871643066),\n",
              " ('Passive-Aggresive', -1.2043052488874233, 0.00657343864440918),\n",
              " ('KNeighborsRegressor', 0.6018406505084566, 0.02986001968383789),\n",
              " ('DecisionTreeRegressor', 0.9999999997137249, 0.012966632843017578),\n",
              " ('RandomForestRegressor', 0.9721440309943423, 2.6890580654144287),\n",
              " ('AdaBoostRegressor', 0.6267497620315605, 0.08448958396911621),\n",
              " ('GradientBoostingRegressor', 0.8149301449902072, 1.4283676147460938),\n",
              " ('XGBRegressor-linear', 0.8755266171463822, 0.7325842380523682)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4WfeYtrQ-z4I",
        "outputId": "feead3dc-7787-4450-b97d-b85f9794ea13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        }
      },
      "source": [
        "Regression_result_df = pd.DataFrame(Regression_result)\n",
        "Regression_result_df.columns = ['Regressor', 'R2-Score', 'Train and test time']\n",
        "Regression_result_df = Regression_result_df.sort_values(by='R2-Score', ascending=False)\n",
        "Regression_result_df['R2-Score'] = (Regression_result_df['R2-Score']*100).round(1).astype(str) + '%'\n",
        "Regression_result_df"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Regressor</th>\n",
              "      <th>R2-Score</th>\n",
              "      <th>Train and test time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>DecisionTreeRegressor</td>\n",
              "      <td>100.0%</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RandomForestRegressor</td>\n",
              "      <td>97.2%</td>\n",
              "      <td>2.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>XGBRegressor-linear</td>\n",
              "      <td>87.6%</td>\n",
              "      <td>0.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>81.5%</td>\n",
              "      <td>1.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>AdaBoostRegressor</td>\n",
              "      <td>62.7%</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>62.3%</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ridge</td>\n",
              "      <td>62.3%</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BayesianRidge</td>\n",
              "      <td>62.3%</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>KNeighborsRegressor</td>\n",
              "      <td>60.2%</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>HuberRegressor</td>\n",
              "      <td>55.2%</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ElasticNet</td>\n",
              "      <td>4.6%</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lasso</td>\n",
              "      <td>4.1%</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LassoLars</td>\n",
              "      <td>0.0%</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Support Vector Machine with RBF kernel</td>\n",
              "      <td>-1.0%</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Linear SVR</td>\n",
              "      <td>-27.1%</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Passive-Aggresive</td>\n",
              "      <td>-120.4%</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SGDRegressor</td>\n",
              "      <td>-1.6031283825632606e+32%</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Regressor                  R2-Score  \\\n",
              "12                   DecisionTreeRegressor                    100.0%   \n",
              "13                   RandomForestRegressor                     97.2%   \n",
              "16                     XGBRegressor-linear                     87.6%   \n",
              "15               GradientBoostingRegressor                     81.5%   \n",
              "14                       AdaBoostRegressor                     62.7%   \n",
              "0                        Linear Regression                     62.3%   \n",
              "2                                    Ridge                     62.3%   \n",
              "5                            BayesianRidge                     62.3%   \n",
              "11                     KNeighborsRegressor                     60.2%   \n",
              "6                           HuberRegressor                     55.2%   \n",
              "3                               ElasticNet                      4.6%   \n",
              "1                                    Lasso                      4.1%   \n",
              "4                                LassoLars                      0.0%   \n",
              "9   Support Vector Machine with RBF kernel                     -1.0%   \n",
              "8                               Linear SVR                    -27.1%   \n",
              "10                       Passive-Aggresive                   -120.4%   \n",
              "7                             SGDRegressor  -1.6031283825632606e+32%   \n",
              "\n",
              "    Train and test time  \n",
              "12                 0.01  \n",
              "13                 2.69  \n",
              "16                 0.73  \n",
              "15                 1.43  \n",
              "14                 0.08  \n",
              "0                  0.01  \n",
              "2                  0.00  \n",
              "5                  0.00  \n",
              "11                 0.03  \n",
              "6                  0.06  \n",
              "3                  0.00  \n",
              "1                  0.00  \n",
              "4                  0.00  \n",
              "9                  0.35  \n",
              "8                  0.13  \n",
              "10                 0.01  \n",
              "7                  0.02  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WqHJdOlW_Sgn"
      },
      "source": [
        "### **Tuning Randomforest model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JlLUzm9HaZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def print_metrics(y_true, y_predicted):\n",
        "    ## First compute R^2 and the adjusted R^2\n",
        "    r2 = sklm.r2_score(y_true, y_predicted)\n",
        "    MAPE = mape(y_predicted, y_true)\n",
        "    # r2_adj = r2 - (y_true.shape[0] - 1)/(y_true.shape[0] - n_parameters - 1) * (1 - r2)\n",
        "    \n",
        "    ## Print the usual metrics and the R^2 values\n",
        "    print('Mean Square Error      = ' + str(sklm.mean_squared_error(y_true, y_predicted)))\n",
        "    print('Root Mean Square Error = ' + str(math.sqrt(sklm.mean_squared_error(y_true, y_predicted))))\n",
        "    print('Mean Absolute Error    = ' + str(sklm.mean_absolute_error(y_true, y_predicted)))\n",
        "    print('Median Absolute Error  = ' + str(sklm.median_absolute_error(y_true, y_predicted)))\n",
        "    print('R^2                    = ' + str(r2))\n",
        "    print('MAPE                    = ' + str(MAPE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fn2zKOcDxsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy.random as nr\n",
        "import sklearn.model_selection as ms\n",
        "\n",
        "nr.seed(123)\n",
        "inside = ms.KFold(n_splits=10, shuffle = True)\n",
        "\n",
        "nr.seed(321)\n",
        "outside = ms.KFold(n_splits=10, shuffle = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-rqEqLG9_Q0m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "71124464-181f-4c21-b5f7-5cea9bb84a87"
      },
      "source": [
        "model_baseline = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
        "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "                      max_samples=None, min_impurity_decrease=0.0,\n",
        "                      min_impurity_split=None, min_samples_leaf=1,\n",
        "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "                      n_estimators=500, n_jobs=None, oob_score=False,\n",
        "                      random_state=123, verbose=0, warm_start=False)\n",
        "\n",
        "model_baseline = model_baseline.fit(X_train, y_train)\n",
        "\n",
        "print(\"Cross-validation accuracy\")\n",
        "cv_estimate = ms.cross_val_score(model_baseline, X_train, y_train, scoring = 'r2',\n",
        "                                 cv = outside) # Use the outside folds\n",
        "print('Mean performance metric = %4.3f' % np.mean(cv_estimate))\n",
        "\n",
        "print('SDT of the metric       = %4.3f' % np.std(cv_estimate))\n",
        "print('Outcomes by cv fold')\n",
        "for i, x in enumerate(cv_estimate):\n",
        "    print('Fold %2d    %4.3f' % (i+1, x))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation accuracy\n",
            "Mean performance metric = 0.777\n",
            "SDT of the metric       = 0.061\n",
            "Outcomes by cv fold\n",
            "Fold  1    0.837\n",
            "Fold  2    0.734\n",
            "Fold  3    0.710\n",
            "Fold  4    0.805\n",
            "Fold  5    0.874\n",
            "Fold  6    0.686\n",
            "Fold  7    0.742\n",
            "Fold  8    0.731\n",
            "Fold  9    0.845\n",
            "Fold 10    0.804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGE7zeVKDxsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "292eecc5-3ba0-46a5-c696-bac06b02c502"
      },
      "source": [
        "nr.seed(3456)\n",
        "## Define the dictionary for the grid search and the model object to search on\n",
        "param_grid = {\"n_estimators\": [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]}\n",
        "\n",
        "## Perform the grid search over the parameters\n",
        "clf = ms.GridSearchCV(estimator = model_baseline, param_grid = param_grid, \n",
        "                      cv = inside, # Use the inside folds\n",
        "                      return_train_score = True)\n",
        "\n",
        "## Fit the cross validated grid search over the data \n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "## And print the best parameter value\n",
        "print(clf.best_estimator_.n_estimators)\n",
        "\n",
        "n_estimators_tuned = clf.best_estimator_.n_estimators"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmAuvQMsDxsk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28e3456e-53f3-4a02-e8ab-385bb44484ab"
      },
      "source": [
        "nr.seed(786)\n",
        "## Define the dictionary for the grid search and the model object to search on\n",
        "param_grid = {\"max_features\": [1,2,3,4,5,6,7, 8, 9, 10, 11, 12, 13, 14, 15, 16,17,18,19,None]}\n",
        "\n",
        "model = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "                      max_features='auto', max_leaf_nodes=None,\n",
        "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                      min_samples_leaf=1, min_samples_split=2,\n",
        "                      min_weight_fraction_leaf=0.0, n_estimators=n_estimators_tuned,\n",
        "                      n_jobs=None, oob_score=False, random_state=123, verbose=0,\n",
        "                      warm_start=False)\n",
        "\n",
        "## Perform the grid search over the parameters\n",
        "clf = ms.GridSearchCV(estimator = model, param_grid = param_grid, \n",
        "                      cv = inside, # Use the inside folds\n",
        "                      return_train_score = True)\n",
        "\n",
        "## Fit the cross validated grid search over the data \n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "## And print the best parameter value\n",
        "print(clf.best_estimator_.max_features)\n",
        "\n",
        "max_features_tuned = clf.best_estimator_.max_features"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFsJjMllDxsu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "c0828971-cedf-4442-8b17-3251ddd13123"
      },
      "source": [
        "nr.seed(786)\n",
        "## Define the dictionary for the grid search and the model object to search on\n",
        "param_grid = {\"min_samples_split\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
        "\n",
        "model = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "                      max_features= max_features_tuned, max_leaf_nodes=None,\n",
        "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                      min_samples_leaf=1, min_samples_split=2,\n",
        "                      min_weight_fraction_leaf=0.0, n_estimators=n_estimators_tuned,\n",
        "                      n_jobs=None, oob_score=False, random_state=123, verbose=0,\n",
        "                      warm_start=False)\n",
        "\n",
        "## Perform the grid search over the parameters\n",
        "clf = ms.GridSearchCV(estimator = model, param_grid = param_grid, \n",
        "                      cv = inside, # Use the inside folds\n",
        "                      return_train_score = True)\n",
        "\n",
        "## Fit the cross validated grid search over the data \n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "## And print the best parameter value\n",
        "print(clf.best_estimator_.min_samples_split)\n",
        "\n",
        "min_samples_split_tuned = clf.best_estimator_.min_samples_split"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htZq7DL4Dxs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3eb37a3d-09c9-43fd-a273-5bd13ad6bb18"
      },
      "source": [
        "nr.seed(786)\n",
        "## Define the dictionary for the grid search and the model object to search on\n",
        "param_grid = {\"min_samples_leaf\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
        "\n",
        "model = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "                      max_features= max_features_tuned, max_leaf_nodes=None,\n",
        "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                      min_samples_leaf=1, min_samples_split=min_samples_split_tuned,\n",
        "                      min_weight_fraction_leaf=0.0, n_estimators=n_estimators_tuned,\n",
        "                      n_jobs=None, oob_score=False, random_state=123, verbose=0,\n",
        "                      warm_start=False)\n",
        "\n",
        "## Perform the grid search over the parameters\n",
        "clf = ms.GridSearchCV(estimator = model, param_grid = param_grid, \n",
        "                      cv = inside, # Use the inside folds\n",
        "                      return_train_score = True)\n",
        "\n",
        "## Fit the cross validated grid search over the data \n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "## And print the best parameter value\n",
        "print(clf.best_estimator_.min_samples_leaf)\n",
        "\n",
        "min_samples_leaf_tuned = clf.best_estimator_.min_samples_leaf"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htePTDQkDxtR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c86a8d0f-1c57-46ad-cbfc-e21a16804165"
      },
      "source": [
        "nr.seed(786)\n",
        "## Define the dictionary for the grid search and the model object to search on\n",
        "param_grid = {\"max_depth\": [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]}\n",
        "\n",
        "model = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "                      max_features= max_features_tuned, max_leaf_nodes=None,\n",
        "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                      min_samples_leaf=min_samples_leaf_tuned, min_samples_split=min_samples_split_tuned,\n",
        "                      min_weight_fraction_leaf=0.0, n_estimators=n_estimators_tuned,\n",
        "                      n_jobs=None, oob_score=False, random_state=123, verbose=0,\n",
        "                      warm_start=False)\n",
        "\n",
        "## Perform the grid search over the parameters\n",
        "clf = ms.GridSearchCV(estimator = model, param_grid = param_grid, \n",
        "                      cv = inside, # Use the inside folds\n",
        "                      return_train_score = True)\n",
        "\n",
        "## Fit the cross validated grid search over the data \n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "## And print the best parameter value\n",
        "print(clf.best_estimator_.max_depth)\n",
        "max_depth_tuned = clf.best_estimator_.max_depth"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RktqOcPDDxtl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0438d9d6-024b-4e2d-e7e3-36bd507b1943"
      },
      "source": [
        "nr.seed(786)\n",
        "## Define the dictionary for the grid search and the model object to search on\n",
        "param_grid = {\"bootstrap\": [True, False]}\n",
        "\n",
        "model = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=max_depth_tuned,\n",
        "                      max_features= max_features_tuned, max_leaf_nodes=None,\n",
        "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                      min_samples_leaf=min_samples_leaf_tuned, min_samples_split=min_samples_split_tuned,\n",
        "                      min_weight_fraction_leaf=0.0, n_estimators=n_estimators_tuned,\n",
        "                      n_jobs=None, oob_score=False, random_state=123, verbose=0,\n",
        "                      warm_start=False)\n",
        "\n",
        "## Perform the grid search over the parameters\n",
        "clf = ms.GridSearchCV(estimator = model, param_grid = param_grid, \n",
        "                      cv = inside, # Use the inside folds\n",
        "                      return_train_score = True)\n",
        "\n",
        "## Fit the cross validated grid search over the data \n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "## And print the best parameter value\n",
        "print(clf.best_estimator_.bootstrap)\n",
        "bootstrap_tuned = clf.best_estimator_.bootstrap"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGqrM0T0Dxtq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a1d6985-7d27-4fd6-cd2a-8a5f50e3dc20"
      },
      "source": [
        "nr.seed(999)\n",
        "## Define the dictionary for the grid search and the model object to search on\n",
        "param_grid = {\"criterion\": [\"mse\", \"mae\"]}\n",
        "\n",
        "model = RandomForestRegressor(bootstrap=bootstrap_tuned, criterion='mse', max_depth=max_depth_tuned,\n",
        "                      max_features= max_features_tuned, max_leaf_nodes=None,\n",
        "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                      min_samples_leaf=min_samples_leaf_tuned, min_samples_split=min_samples_split_tuned,\n",
        "                      min_weight_fraction_leaf=0.0, n_estimators=n_estimators_tuned,\n",
        "                      n_jobs=None, oob_score=False, random_state=123, verbose=0,\n",
        "                      warm_start=False)\n",
        "\n",
        "## Perform the grid search over the parameters\n",
        "clf = ms.GridSearchCV(estimator = model, param_grid = param_grid, \n",
        "                      cv = inside, # Use the inside folds\n",
        "                      return_train_score = True)\n",
        "\n",
        "## Fit the cross validated grid search over the data \n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "## And print the best parameter value\n",
        "print(clf.best_estimator_.criterion)\n",
        "criterion_tuned = clf.best_estimator_.criterion"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nnvl4ttJ_0Lo",
        "colab_type": "text"
      },
      "source": [
        "### **Final Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hjn9ph4_5hg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "081a1cdb-146c-4a06-d01f-7cfc1c080e51"
      },
      "source": [
        "model = RandomForestRegressor(bootstrap=bootstrap_tuned, criterion=criterion_tuned, max_depth=max_depth_tuned,\n",
        "                      max_features= max_features_tuned, max_leaf_nodes=None,\n",
        "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                      min_samples_leaf=min_samples_leaf_tuned, min_samples_split=min_samples_split_tuned,\n",
        "                      min_weight_fraction_leaf=0.0, n_estimators=n_estimators_tuned,\n",
        "                      n_jobs=None, oob_score=False, random_state=123, verbose=0,\n",
        "                      warm_start=False)\n",
        "\n",
        "model = model.fit(X, y)\n",
        "\n",
        "print(\"Cross-validation accuracy\")\n",
        "cv_estimate = ms.cross_val_score(model_baseline, X, y, scoring = 'r2',\n",
        "                                 cv = outside) # Use the outside folds\n",
        "print('Mean performance metric = %4.3f' % np.mean(cv_estimate))\n",
        "\n",
        "print('SDT of the metric       = %4.3f' % np.std(cv_estimate))\n",
        "print('Outcomes by cv fold')\n",
        "for i, x in enumerate(cv_estimate):\n",
        "    print('Fold %2d    %4.3f' % (i+1, x))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation accuracy\n",
            "Mean performance metric = 0.783\n",
            "SDT of the metric       = 0.053\n",
            "Outcomes by cv fold\n",
            "Fold  1    0.822\n",
            "Fold  2    0.792\n",
            "Fold  3    0.716\n",
            "Fold  4    0.858\n",
            "Fold  5    0.783\n",
            "Fold  6    0.786\n",
            "Fold  7    0.778\n",
            "Fold  8    0.695\n",
            "Fold  9    0.742\n",
            "Fold 10    0.863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V5qXzcMYCOJm"
      },
      "source": [
        "## **Predicting test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "clMJ3POJCSLs",
        "outputId": "5f5629fa-7844-4ef1-f4ab-6add4f5394ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_v2 = test.drop(['id'], axis = 1)\n",
        "test_v2 = feature_eng(test_v2)\n",
        "\n",
        "print(\"Shape of features :\", test_v2.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of features : (182, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9JYwdTC-CuHK",
        "outputId": "d9e99932-ee03-4728-dddc-f566b0c71a4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "feature_list = X.columns.tolist()\n",
        "dummy_add = list(set(feature_list) - set(test_v2.columns))\n",
        "\n",
        "for newcol in dummy_add:\n",
        "    test_v2[newcol] = 0\n",
        "\n",
        "test_v2 = test_v2[feature_list]\n",
        "test_v2.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>segment</th>\n",
              "      <th>Holiday_flag</th>\n",
              "      <th>Diwali_HOLIDAY</th>\n",
              "      <th>Dussehra_HOLIDAY</th>\n",
              "      <th>year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Date</th>\n",
              "      <th>Month_Index</th>\n",
              "      <th>Date_index</th>\n",
              "      <th>weekday_Friday</th>\n",
              "      <th>weekday_Monday</th>\n",
              "      <th>weekday_Saturday</th>\n",
              "      <th>weekday_Sunday</th>\n",
              "      <th>weekday_Thursday</th>\n",
              "      <th>weekday_Tuesday</th>\n",
              "      <th>weekday_Wednesday</th>\n",
              "      <th>Seasons_Monsoon</th>\n",
              "      <th>Seasons_Summer</th>\n",
              "      <th>Seasons_Winter</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2019</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   segment  Holiday_flag  Diwali_HOLIDAY  Dussehra_HOLIDAY  year  Month  Date  \\\n",
              "0        1             0            0.00              0.00  2019      7     6   \n",
              "1        1             0            0.00              0.00  2019      7     7   \n",
              "2        1             0            0.00              0.00  2019      7     8   \n",
              "3        1             0            0.00              0.00  2019      7     9   \n",
              "4        1             0            0.00              0.00  2019      7    10   \n",
              "\n",
              "   Month_Index  Date_index  weekday_Friday  weekday_Monday  weekday_Saturday  \\\n",
              "0         1.00        0.50               0               0                 1   \n",
              "1         1.00        0.50               0               0                 0   \n",
              "2         1.00        0.50               0               1                 0   \n",
              "3         1.00        0.50               0               0                 0   \n",
              "4         1.00        0.50               0               0                 0   \n",
              "\n",
              "   weekday_Sunday  weekday_Thursday  weekday_Tuesday  weekday_Wednesday  \\\n",
              "0               0                 0                0                  0   \n",
              "1               1                 0                0                  0   \n",
              "2               0                 0                0                  0   \n",
              "3               0                 0                1                  0   \n",
              "4               0                 0                0                  1   \n",
              "\n",
              "   Seasons_Monsoon  Seasons_Summer  Seasons_Winter  \n",
              "0                1               0               0  \n",
              "1                1               0               0  \n",
              "2                1               0               0  \n",
              "3                1               0               0  \n",
              "4                1               0               0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hC8GpD_5kFBM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "88d90670-a020-47de-fed0-daa3555a5365"
      },
      "source": [
        "test_v2 = test_v2.drop_duplicates()\n",
        "test['case_count'] = np.exp(model.predict(test_v2))\n",
        "test['case_count'] = test['case_count'].round(0)\n",
        "test.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>application_date</th>\n",
              "      <th>segment</th>\n",
              "      <th>case_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2019-07-06</td>\n",
              "      <td>1</td>\n",
              "      <td>1910.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2019-07-07</td>\n",
              "      <td>1</td>\n",
              "      <td>1288.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2019-07-08</td>\n",
              "      <td>1</td>\n",
              "      <td>2883.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2019-07-09</td>\n",
              "      <td>1</td>\n",
              "      <td>2809.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2019-07-10</td>\n",
              "      <td>1</td>\n",
              "      <td>2977.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id application_date  segment  case_count\n",
              "0   1       2019-07-06        1     1910.00\n",
              "1   2       2019-07-07        1     1288.00\n",
              "2   3       2019-07-08        1     2883.00\n",
              "3   4       2019-07-09        1     2809.00\n",
              "4   5       2019-07-10        1     2977.00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wZ-LU4oDxuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Submission = test[['id', 'application_date', 'segment', 'case_count']]\n",
        "\n",
        "Submission.to_csv(\"./Output/Submission_RF_v6.csv\", index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}